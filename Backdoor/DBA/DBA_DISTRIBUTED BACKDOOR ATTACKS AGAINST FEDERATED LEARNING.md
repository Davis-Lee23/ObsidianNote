
# Note
centralized backdoor集中式后门

# Abstract
动机：联邦学习需要聚合不同方提供的参数这可能存在某些漏洞，想提出一种新的威胁评估框架。
方法：DBA不同于集中式后门（恶意客户端都是一样的触发器），它讲全局触发器分解到不同的本地客户端中。
结果：持久性和隐蔽性都更好，成功率显著高于集中式后门。此外还对局部触发器进行了各种测试，证明了优越性。

# Introduction
联邦学习聚合各方数据训练模型，它天生的分布式与异构性带来了潜在的威胁。那些用一模一样触发器的称之为centralized backdoor，本文提出了distributed backdoor——DBA，将全局触发器分散到不同的恶意客户端上。

贡献总结如下：
1. 提出了新颖的DBA，该方法无论在single-shot还是multiple-shot都更加优越
2. 能避开两种SOTA方法，stealthy & effective
3. 从特征视觉解释和特征重要性排序两个角度对DBA进行了深度解释
4. 全面分析、消融实验

# Method
### Background
1. 介绍了一堆FL公式。
2. 攻击者能力：可以控制本地，但不能影响服务器，例如篡改聚合规则，也不能影响正常客户端训练。
3. 目标：误导模型将带触发器的图像识别为target

### DBA
以下图为例，集中式的有四色触发器，DBA切分为四份，每个恶意者只有部分的触发器。
编写了数学公式，并且从实验结果出发，虽然DBA的恶意者没见过完整的，但就是更好。
![[Pasted image 20240920214032.png]]

### Factors in DBA
探讨了后门攻击的多方面因素影响，包括触发器大小TS、触发器间距TG、触发器位置TL
![[Pasted image 20240920215022.png]]

此外还有
缩放因子：没太懂，看看代码
中毒率：训练数据的后门比例、过大可能导致模型报废
中毒间隔：I=0意味着一直投毒，I=1意味着间隔一轮
数据分布：采用迪利克雷分布

# Experiment
## 实验设置
数据集：LOAN、MNIST、CIFAR10、Tiny-imagenet
![[Pasted image 20240920201456.png]]
划分：noniid
超参数：bs=64

## 实验方案
### 分布式对比集中式



### DBA的鲁棒性


### 对特征的解释


# Analysis



