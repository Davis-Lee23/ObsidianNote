
# Authors
Moran Baruch 巴伊兰大学，资料较少

# Abstract
**背景：** 分布式学习会受到拜占庭参与者的攻击导致学习过程被中断或操控。
**动机**：过去的模型假设攻击者a）全知全能 b）大幅改变了参数，显然各种统计学的防御就可以抵御。
**方法**：攻击者利用这些经验主义的界限来攻击，甚至可以让服务器一直选择恶意参与者。
**结果**：该方法不仅可以阻止收敛，也适用于后门。MNIST和CIFAR-10需要25%，CIFAR100需要50%。


# Experiments
