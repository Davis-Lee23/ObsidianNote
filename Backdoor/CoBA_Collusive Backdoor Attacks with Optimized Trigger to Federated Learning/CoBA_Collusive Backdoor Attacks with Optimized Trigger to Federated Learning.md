# 摘要
动机：尽管当前有大量对FL后门攻击的研究并且取得了不错的成果，但这只是一种虚假的安全感，共谋攻击者仍可以有效的执行后门攻击。

方法：提出了Collusive Backdoor Attack（CoBA），CoBA旨在通过提供触发器调整来促进后门训练数据的学习，控制恶意本地模型更新的偏差，并应用投影梯度下降技术，从而增强后门攻击的稀疏性和隐蔽性。

结果：
1. CoBA成功规避了15种最新的鲁棒FL防御方法
2. CoBA（场景？性能？）
3. CoBA仅需少量轮次就可以实现很好的结果

# Introduction
FL易收到后门攻击，后门攻击相比于无目标攻击更隐蔽、威胁更大。
当前后门攻击大都存在同样的局限：
1. 后门攻击希望让触发器与目标类建立关联，然而随意设计的触发器可能让中毒局部模型明显偏离于全局模型，一些鲁棒方法很容易就可以检测出来。
2. 大部分攻击方法都是独立攻击，没有考虑共谋，无共谋情况下的后门攻击很难抑制后门诱导的偏差来逃避检测，这使得它们容易受到针对sybil攻击的防御方法的防护。
3. 联邦学习存在随机选择的过程，恶意者比例相对较小需要经过多轮训练才能植入后门，大多数研究忽略了攻击成本（迭代轮次）的问题。
基于以上，作者认为一个优秀的后门攻击方法要兼具sparsity和stealthiness，稀疏性就是用较少轮次实现攻击，攻击成本低。

---
本文针对的场景是non-iid with partial participation。
本文是一篇会议的拓展，主要做了三个方面的改进：
1. 改进了触发器优化，显式操纵恶意局部模型偏差以及应用投影梯度下降技术来显着增强CoBA攻击方法。
2. 新加了俩攻击模式评估隐蔽性和稀疏性，更加严谨。
3. 拓展了评估，增加了数据集和场景。

**对于隐蔽性**，最为重要的就是减少中毒与无毒模型之间的偏差。作者利用了优化后门触发器与显式控制控制中毒本地模型偏差的方法来减轻触发器对全局模型的影响。
1. 首先，作者提出在攻击期间优化后门触发器，旨在最小化中毒训练数据的分类风险，从而减少中毒局部模型的参数变化。（？）
2. 攻击者共同减少中毒局部模型的偏离。在全局上，最小化中毒局部模型和之前聚合的全局模型的差异；在局部上，最小化中毒后的局部模型与无毒模型没有差异。
3. 尽可能让恶意者的本地模型不尽相同，扩大中毒模型的局部分歧以逃避对Sybil攻击的防御

对于**稀疏性**，来源于直觉——最小化后门样本在无毒模型上的损失，这将有助于模型学习后门样本。从结果上看，这种做法大幅提升了收敛速度，减少了所需攻击轮次。作者引入了攻击期间后门触发器的优化处理，该方法能自动改变触发器以最小化与中毒训练数据相关的中毒风险。此外CoBA还用了投影梯度下降技术而非SGD来提高了稀疏性和中毒的持续性。

贡献总结：
1. 提出了CoBA，一种在隐蔽性、稀疏性、可持续性都有显著提升的FL后门攻击方法
2. 将CoBA攻击视作一个优化问题，它能优化后门触发器和控制本地中毒模型后门引起的变化，因此CoBA可以避开主流防御方法。
3. 大量实验

# Background
介绍了后门的发展历程，多种攻击手段、多种防御手段

# Problem Definition

+ System model：横向联邦学习。Non-IID且Partial participation。定义了一堆符号。
+ Adversary's goal：一是完成基本目标，二是有防御方法下也可以实现高ASR，三是尽可能减少攻击轮次
+ Adversary's capability：恶意客户端会共享中毒本地模型，但无法访问服务器和良性客户端。
+ Adversary's knowledge：攻击者不知道服务器的聚合规则，也不知道良性参与者的数据和模型，只知道共谋者的数据和训练过程。
+ Attack mode：分为持续攻击和间歇攻击。
	+ 持续攻击：恶意客户端被选中就攻击，用以评估后门攻击的隐蔽性，ASR越高隐蔽性越强。
	+ 间歇攻击：专注于评估各防御方法下实现攻击的最小轮次。遵从以下规则：攻击直到达到某个阈值，ASR低于阈值后再次发起攻击。由于选择的随机性，该方法还可以评估中毒效果的持久性。

# CoBA
算法图概览：G全局模型，L本地模型，这掩码干啥的？
![[Pasted image 20240904150856.png]]

CoBA可以形式化的定义为一个优化问题：核心就是这一大串对于恶意客户端的损失函数（i,i' ∈ S）
l=loss，损失函数，代表对数据实例（x，y）的结果。第一个是正常数据，第二个是后门数据。Fro代表F范数（Frobenius norm）,cs（cosine similarity）代表余弦相似度。
我们将触发器Δx视为一个变量，用参数φ限制优化触发器与原始触发器的距离。
![[Pasted image 20240904151049.png]]

---

更具体地说，这个式子从五个方面优化了CoBA。
1. 学习后门的同时保持了正常任务的性能。前俩项
2. 优化了后门触发器。在第二项中Δx被视为了一个变量用以最小化中毒训练数据的损失
3. 最小化本地中毒模型的偏差。为了绕过防御方法，本文从两方面显式的最小化了中毒模型的参数变化。本地模型方面用F范数拉近所有loss与良性数据loss之；全局模型方面，拉近所有loss与G。（intuition）
4. 放大中毒模型之间的方差。增加恶意参与者提交的本地模型的多样性以绕开防御sybil攻击的措施。
5. 基于投影梯度下降的后门中毒持续影响（不太懂，反正就是能做到）。



# 实验

### 实验设置
数据集：cifar10、cifar100（resnet18）、mnist、fmnist（卷积1）、loan（3fc）
触发器：24pixels/bird ； 24pixels/fish ; 20x20pixels/1;  20x20pixels/Trouser ; 31特征的trigger/Fully Paid
数据切分：noniid，迪利克雷分布α=0.9，LOAN单独处理
后门基线方法：四种分布式后门攻击方法
1. ModelRe：用λ放大中毒模型
2. LIE：使用clamping regularization裁剪中毒模型参数
3. Sybil attack：恶意者不共谋的学习常见后门触发器
4. DBA：不同恶意客户端不同触发器
客户端选择：前四个100选10，loan 80选10
##### 超参数设置
训练算法为FedAvg，学习率lr=1，α、β、γ都为0.0001，gradient mask=0.99，φ好像用来限制优化触发器与初始触发器的距离，还需要看原文。

##### 攻击设置
N：所有，C：恶意
**趋于收敛之后才开始攻击**
![[Pasted image 20240903183111.png]]

攻击模式分为：持续攻击、间歇攻击。

##### 指标
持续攻击：ACC、ASR
间歇攻击C=Iatk / Isum，atk意味着让asr达到80%以上的轮次。作者直接用Iatk当作测量稀疏性sparsity的指标，Fewer attack iterations denote sparser attacks against the defense methods in intermittent attack mode.


### 实验结果对比
表2-5，持续攻击的结果，ACC与ASR大部分优
图a-b，间歇攻击的结果，需要的轮次少

1. 实验结果表明CoBA不会影响正常的分类正确率
2. CoBA的ASR大部分场景下优于其他方法，没有一个baseline可以在所有防御方法下都逼近CoBA的ACC和ASR（隐藏性好，此处科普了其他方法缺点）
3. CoBA仅需少轮次即可达到高ASR，展现出了high sparsity

总而言之触发器的优化和中毒局部模型更新的控制对于FL中**隐秘stealthy和稀疏sparsity**后门攻击的成功至关重要。
1. stealthy：除了前文大量实验，还在附录中展示了CoBA投毒后的模型与无毒模型有最小的欧几里得距离。
2. sparsity：大量实验表面CoBA收敛的更快，并且在停止攻击后中毒效果更持久

### 消融实验
**触发器优化** 