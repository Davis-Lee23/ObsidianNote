在黑暗中验证：使用隐形后门触发器解锁可验证机器遗忘

>动机
>技术路线
>实验结果-实验数据集，实验设置，评价标准（metric）
### 聊天记录：
Backdoor-Assisted Validation: Utilizes backdoor triggers to embed invisible markers in privacy-sensitive data,因为他这个方法就是借鉴别人文章中，他拿来用于mu的验证

先看3的动机，怎么讲这个不可见后门的故事，为什么要用不可见后门，怎么评估这个不可见后门，评估指标。
然后看1他在中心化场景下怎么做这个不可见后门，然后看2在联邦下不可见后门怎么构造的
然后这样子的话一整个验证体系我们就有了，然后找遗忘方法。
那么此时5就是一个损失函数的设计，可能就需要研究下怎么设计这个遗忘方法

遗忘的描述就一般是为了隐私保护什么的，现在需要我们**调研下这个不可见后门的动机**

## 动机
文章的假设用户是可信的。
### 摘要版
+ 当前并**没有高效的**机器遗忘验证方法，也无法保证遗忘后再训练的效率以及服务质量。此外，关于如何设计出有效的验证方案以防止服务提供者制造虚假证据来欺骗验证，这一领域仍未充分探索。
+ 提出嵌入Invisible Backdoor Trigger不可见后门触发器到一些敏感数据中，之所以不可见是为了不让provider分别出哪些是"有毒"数据，即客户端嵌入后门触发器的数据。
+ 作者设计了一种索引架构并使用增量学习提高了再训练效率。


## 技术路线
### 增量学习
为提升再训练的效率，作者采用增量学习，该部分采用他人提出的LWF算法实现。

### 后门攻击
这一部分采用LSB(Least Small Bit)最低有效位算法去注入trigger。
图片一般由RGB三原色组成，每一种原色占8bits，三色组成的颜色的可能性就有2^8^3约1600万种，人的肉眼无法分辨细微的变化(**但DNN仍然可识别**)。
因此我们可以在像素的末位修改bit值，组成我们的触发器。
![[Pasted image 20240204225557.png]]

博客资料：
1. [LSB算法分析与实现-CSDN博客](https://blog.csdn.net/qq_38768365/article/details/102494128
2. [LSB图片隐写(最低有效位隐写) - QIONGKE - 博客园 (cnblogs.com)](https://www.cnblogs.com/qiongke/p/15112057.html)

### 为什么要采用不可见后门？
+ 根据RTBF(right to be forgotten)，数据拥有者应有让服务提供者准确遗忘数据的权利。
+ 当前确实存在一些方法可以精准的遗忘数据，但是这都建立在服务提供者是诚实的前提下才得以实现，如果服务提供者伪造遗忘证明，那么大量隐私数据将被泄露。
+ 部分研究采用可信执行环境TEE解决了该问题，但这需要服务提供者使用可信硬件，让提供者主动安装，这并不太可能。
+ 从另一个角度讲，验证服务器的机器遗忘能力有助于提高整个联邦学习系统的安全性，并且可以让参与者对系统更有信心，更愿意加入该系统。

### 实验数据集
MNIST
CIFAR10
GTSRB

### 实验设置
**软/硬件：** PyTorch1.8.1 / RTX3060
**模型：** 以ResNet34为基本模型，下面是无中毒数据的正确率
![[Pasted image 20240208195312.png]]
**trigger长度：** 基于已有研究，长度500作为最优选项
此外，通过PASS值对比BadNets，该方法的不可见率更高
![[Pasted image 20240208203945.png]]
![[Pasted image 20240208211013.png]]
**标记注入时间：** 即使中毒率80%，额外损耗的时间也在0.8s以下，属于可接受范围
![[Pasted image 20240208210421.png]]


### 评价标准（metric）

后门攻击有两个重要的评价标准
1. backdoor attack success rate(BASR)
	+ BASR表示神经网络对中毒数据的测试精度，我们可以利用这一特点来判断服务提供者是否删除了我们的数据，如果诚实删除了数据，那么BASR将会急剧下降。
2. clean sample accuracy(CSA)
	+ CSA表示神经网络在干净数据上的测试精度。我们的标记应该只影响BASR，不影响CSA。

综上所述，用BASR判断服务提供者是否删除数据，差异大代表有删除。我们使用CSA判断是否影响模型性能，差异不大即没有影响。通过比较传统的从头开始训练和使用增量学习的断点再训练两种方法的BASR和CSA结果，来全面评估本文提出的后门辅助验证方案。

实验分别测量了以下四个变量对模型精度的影响
1. 中毒率(不做变量时为0.5)
2. 删除数据的类别数(不做变量时仅有1类)
3. 测试图像的数量(不做变量时为100)
4. 用户数量(不做变量时为单用户)

## 实验结果

#### 从头开始再训练(传统方法)
![[Pasted image 20240212145845.png]]
![[Pasted image 20240212145921.png]]
#### 从断点开始再训练(增量学习)
![[Pasted image 20240212150257.png]]
![[Pasted image 20240212150308.png]]

#### 两种方案对比：
验证效果：BASR差异得到提升
![[Pasted image 20240212150532.png]]
时间开销：用户越多，增量方法性能提升越明显
![[Pasted image 20240212152002.png]]
PRF(pseudo random function)的效果:这里有点不明所以，也没有对照组
![[Pasted image 20240212152853.png]]

### 未来展望
1. 将本文的研究应用在NLP上
2. 将本文的研究应用在FU联邦遗忘上