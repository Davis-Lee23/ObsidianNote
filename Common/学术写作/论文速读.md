# 顺序01 Video Google，这是Base

Title: Video Google: A Text Retrieval Approach to Object Matching in Videos

### Abstract
本文提出一种对对象和场景检索的方法，该方法回搜索和定位视频中用户概述目标所有出现场景。
具体实现。。。

### Introduction
该工作的目的是能轻松快速的检索到视频中包含指定物品的关键帧、镜头，就像 Google 检索包含特定单词的文本文档（网页）一样轻松、快速和准确。

文章中用两种区域作为一帧图像的visual words，当然要成为visual words还要对区域进行特征描述，这里作者倒是想到用sift的特征描述方法了，文章中也提到了所选的特征和特征描述方式满足仿射不变性，有利于区域不同尺度不同视角的匹配。另外，这里的区域提取都是在灰度图中实现的，并没有用到图像的色彩信息，并且一帧图像中提取出的区域要和相邻几帧进行比较，若该区域只出现在当前一帧图像上，就会把该区域当成噪声或不稳定区域舍去。有了visual words之后便要构造相应的字典（visual vocabulary），这里是将文章中提到的两部视频按48个镜头大约10000帧的图像进行visual words的提取，然后将提取到的visual words用K-means的方法进行聚类，得到一副词典，这样每帧图像我们就可以像文字检索中的一篇文档那样，用词典中相关词的频率来描述。这里作者提到了关于SA和MS区域两种描述子的聚类过程是相互独立的。至于聚类过程中聚类中心的选取、K值的选择、两种区域的比例，文章中一句话带过，这些都是经过多次试验得到的经验值（貌似很多文献中相关参数的选择都会这么一笔带过）。后面又将文字检索中加权的思想引入到视频检索中来，也就是说对一些经常出现的visual words赋予较小的权重，对于一些不经常出现或者类似“关键字”之类的赋予一个较大的权值，这个就不是这篇文章的重点了。


# 顺序02 Joint Optimization Toward Effective and Efficient Image Search



# 顺序03 Scalable Recognition with a Vocabulary Tree

受到01启发。