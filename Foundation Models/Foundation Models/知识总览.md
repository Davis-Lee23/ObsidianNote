# 大模型介绍
[(4 封私信) 什么是大模型？超大模型和 Foundation Model 呢？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/498275802)

首先明确一个概念，Foundation Model，就是大模型。2021年李飞飞等人发表了一份关于大模型的综述，指出大模型出现了**涌现(Emergence)** 和**同质化(Homogenization)** 的特性。 

涌现不是显式的，而是隐性推动的，ML - DL - FM
同质化即下游产物会继承上游产物的特点，无论优缺点。

## 大模型的作用

1. **模型碎片化，大模型提供预训练方案** 
	定制化服务很难，因此提供了预训练大模型+下游任务微调
	
2.  **大模型具备自监督学习能力，降低训练成本**
	用自监督的方法解决了人工标注的高成本问题，参数规模越大优势越明显
	
3. 大模型的出现有助于突破现有模型的精度局限
	10年代早期深度学习聚焦于网络结构的变革，到了瓶颈。研究表明模型和数据规模的增大确实可以突破现有的精度。



# FL & FM
[联邦学习系列|Foundation Model×Federated Learning - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/660573898)

### 1、介绍
FL可以扩展大模型获取知识的途径，并且可以实现计算共享，降低了大模型训练过程的负担，促进协作式大模型的发展。
FM规模大，预训练知识储备充足且性能出色为FL提供了好的起点在Non-IID数据下可以实现更快的收敛和更好的性能。

因此我们有两个侧重点：
1. FL for FM，Federated FM，用联邦学习去做大模型，重点是大模型
2. FM for FL，FM's FL，用大模型去解决联邦学习问题，重点是联邦

### 2、FL for FM
##### Motivation
1. 大规模高质量合法数据的短缺
2. 高性能计算资源短缺
3. 巨头公司的垄断，小公司协作才有出路
4. 数据隐私和控制
5. 本地部署提升用户体验，传统大模型是给API权限，联邦可以在本地部署

##### Challenges
1. 大模型要求高内存、通信、计算能力。部署大模型要消耗大量资源，数据传输也很考验带宽
2. 暂时还未有联邦大模型的隐私协议，且多个客户端知识融合可能有安全漏洞。
3. 知识产权和版权问题，需要unlearning
4. 协作激励机制

##### Future
1. 将FL整合到大模型生命周期中，无论是预训练、微调、下游应用（？）
2. 减少内存、通信、计算开销。期望将来有**高效的分布式学习算法、PEFT（Parameter-Efficient FIne-Tuning）**，现有方法一般是冻结+调整特定层，仍不够高效。**Prompt tuning**在资源受限、敏感的环境下不可行。**模型压缩技术**，例如剪枝、量化、NAS、蒸馏、迁移学习
3. 设置联邦学习大模型基准
4. 分散的数据，使得大模型更加全面，可能提高性能。
5. 提升FL的安全性以服务大模型。
6. 探索激励机制

### 3、FM for FL

##### Motivation
1. FL的数据隐私和短缺困境。FL中客户端可能只有有限或不平衡的数据，并且一些敏感数据可以从模型更新中恢复。大模型中的**生成和使用合成数据**是一种有前景的方法。跨机构的FL中，客户端可以自己合成数据，跨设备的FL则需要服务器生成，交给客户端训练。这样可以缓解数据稀疏问题，引入多样性减少过拟合，保护隐私。
2. FL的性能瓶颈。预训练的大模型可以作为FL的起点，加快收敛减少通信轮次，以减少大量的通信开销。大模型作为强大的生成模型可以合成多样化的数据以丰富联邦学习的训练数据。大模型可以通过知识蒸馏，把自己当作教师的角色教导FL中的简单模型，改善性能和泛化能力。
3. 新的参数共享范式。利用prompt tuning，而不是传统的共享高维参数。

##### Challenges
1. 要合法、负责的使用。大模型记忆力强，可能直接从训练集合成过于相似的数据。
2. 生成的数据存在问题。一数据源要靠谱，二合成数据也可能过拟合。
3. FM整合到FL中的独特挑战：
	1. 大部分FL都是有标签的，但实际场景可能标签稀疏或无标签。**需要有无监督or半监督FL**
	2. 数据是以连续流的形式到达而不是静态批次，FL需要有效地适应大模型的持续学习（？）。
	3. FL数据存在领域差距。训练集和测试集很可能存在显著差异，因此需要研究自适应技术，例如**迁移学习和领域对齐**。
	4. FL的数据和系统异质性，可以考虑PFL和自适应学习策略。
	5. 训练数据过时问题。这个没太看懂，不过这个问题很久之前就考虑过了，同步的训练显然不切实际，普通的异步方法可能出现老旧的更新，有没有完美的异步方法呢？
	6. 动态大模型。
	7. 黑白盒大模型。目前大都是以API黑盒方法访问模型，在没有白盒的情况下，如何将FM的优点应用到FL具有挑战性。

##### Future
1. 合法合规的将FM应用于FL
	1. 合成数据的验证，不能和真实数据太接近
	2. 隐私保护。没看懂，反正又是数据合成、知识蒸馏
	3. 跨学科
2. 鲁棒性
	1. 对抗偏见的鲁棒性，即bias
	2. 提升合成数据的质量和多样性
	3. 对中毒模型的鲁棒性提升。比如具有后门的扩散模型，研究遗忘？更鲁棒的知识蒸馏？
	4. 拜占庭攻击、对抗样本的鲁棒性。拜占庭攻击者引入对抗提示，就可能以很简单的方式破坏了FL（有待学习）
3. PFL
	1. PFL适用于异质客户端
	2. 解决数据不平衡和领域迁移问题
	3. 个性化数据生成
4. 更先进的知识蒸馏
	1. 传统蒸馏针对于集中式数据，可以尝试开发针对FL而当特定蒸馏。可以从降低成本，FL的公平和保护隐私，黑盒知识蒸馏入手。
5. 现在，开始尝试将FM融入到FL吧！Hugging Face等社区提供了许多可用大模型，总的来说困境有①FL如何处理无标签数据 ②如何应对领域差距 ③如何应对持续变化的环境
