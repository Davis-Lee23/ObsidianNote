### Motivation
由于FL和ML固有的差别，当前仍没有FU方法。首次提出FU，用空间换时间的思路，通过一种校正方法在保持性能的同时显著减少了构建遗忘模型的时间。

贡献小结：
1. 提出FedEraser可以遗忘，并且可以作为一个组件移植
2. 利用存储-校正技术解决参数前向耦合的问题，可以在性能不变情况下加速
3. 新的指标，遗忘模型和重训练模型的参数差异，验证有效性

### Method
分为四步：①校准训练 ② 更新校准 ③校准聚合 ④更新遗忘
人话：选择一些比较近的客户端，看代码注释即可

经过我的研究，实际上遗忘的时长，和你的间隔设置关系非常大

训练提升的速度 = 1/r ✖ Δt，即1/本地校正轮次比例 ✖ 间隔

### Experiment
数据集&模型：
![[Pasted image 20240324161612.png]]

超参数设置：r=0.5, t=2
评价标准：acc，loss，time，**prediction difference** ，MIA的攻击精度、召回率
预测参数的差异，还用了个角度图
#### 实验结果：
对比了蛮多东西，不过cifar明显造假+不全
比较了r的影响，t的影响，clients
r：越大，Test和Target越差，Time也多
t：越大，双双更好，Time也少
clients：非常的断章取义，但总的越大，效果越好

### Pros and Cons
优点：
1. idea很有信息，存储+校正
2. 速度确实快了
3. 理论上确实是可适配所有代码

缺点：
+ 代码角度，显然有很多可提升的空间，部分地方和文章有冲突
+ **存储**开销太大了
+ 实验做的依托史，估计硬件跟不上
### Comments
idea很有创新，虽然实验做得很差，但是也无愧CCF-B了。代码部分遗忘那块明显有提升空间。此外作者称展望有实例级遗忘，无客户端帮助训练的遗忘，遗忘验证。