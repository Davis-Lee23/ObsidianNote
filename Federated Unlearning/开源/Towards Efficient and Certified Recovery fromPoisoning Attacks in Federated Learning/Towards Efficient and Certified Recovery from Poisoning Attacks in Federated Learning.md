tayo### 摘要
动机：尽管已有多种方法防御来自FL客户端的攻击，但当检测到恶意客户端时模型已经受到了影响，因此需要一种方法恢复模型。当前当前恢复方法依赖于**所有历史信息**和**初始模型**，二者导致了高存储和高计算开销

方法：提出Crab，一种基于选择性信息存储和自适应模型回滚的高效有效恢复方法①选择性的存储历史信息②选择未受到深影响的历史全局模型，而非初始模型。此外进行了一种证明Crab恢复的全局模型与从头开始训练恢复的全局模型之间的差异是有界的。

结果：在三个数据集上实验各种无目标和目标攻击，证明Crab准确高效，且在恢复速度和内存方面优于过去的方法。

FL容易受到投毒攻击，当发现中毒后模型已经聚合了有毒信息，需要一种恢复方法（遗忘）来解决该问题。当前恢复方法依赖于**所有历史信息**和**初始模型**。提出Crab，一种利用选择性信息和自适应回滚的恢复方法，且仅需没有被深刻影响的模型。

### 介绍
FL容易受到攻击，一是无目标攻击，二是有目标攻击，无论哪种都可以快速影响模型，并且造成深远的影响。重训简单有效，但是消耗通讯、计算太多。然后又介绍了存储-校准方法，计算和存储消耗太多。
此时作者观察到历史信息对全局模型重要性有差异，且刚攻击的几轮全局模型影响不深。提出了Crab，一种依赖于选择性存储和自适应模型回滚。作者认为该方法显著减少了存储空间和计算成本，主要一些在性能上的trade-off。

贡献总结：
1. 提出Crab，高效且有效。
2. 提出了俩策略，选择性存储和自适应模型回滚
3. 理论证明了Retrain最好
4. 在三个数据集上实验了目标、无目标攻击

### Preliminary 
##### FL：讲的还行
##### Poisoning Attack
无目标：Trim，Local Model Poisoning Attacks to Byzantine-Robust Federated Learning
有目标：后门

一堆符号

### Problem Definition
沿用FedRecover的威胁模型

Certified recovery，用重训来当作标准，越接近越好
Cost-effective recovery，内存
Fast recovery，轮次应该少

### Design of Crab
两件套+理论分析

##### 选择性存储
**轮次选择**
用KL散度衡量两轮训练之间的差异，<font color="#ff0000">KL散度可以量化两个概率分布之间的差异</font>，KL散度越大表明变化越显著。用一个时间窗口存储轮次更新（缓存），来决定留下哪些更新

**客户端选择**
每一轮的客户端的贡献度不同，选择存储影响大的客户端。<font color="#ff0000">利用余弦相似度衡量贡献</font>，越高代表贡献越多

##### 自适应模型回滚
过往的恢复都是从初始模型开始，而实践证明影响不深开始回滚也可以。
用sensitivity analysis衡量输入变化如何影响输出，引用42-44。


### Experiment

#### 实验设置：
超参数：20客户端随机选70%（δ=0.7），5局部轮次，40全局，lr=0.005，batchsize=64
攻击方法：后门攻击（0.1，0.25，0.5）、Trim攻击（10%）
超参数：自适应回滚β=0.3，轮次选择λ=0.6，δ=0.7
基线：重训，FedEraser，FedRecover
评价标准：Test Accuracy，BASR，MISR，Running Time
数据集：MNIST，FMNIST，CIFAR-10（有点太简单了）
#### 实验结果：
##### 内存和计算开销表达式：
内存：
	重训和FR：CMT
	FE：CMT/Δt
	Crab：λδCMT
计算：
	重训：O（T）
	FE：T/Δt
	FR：复杂式子
	Crab：λT-j*
![[Pasted image 20240710170651.png|500]]

##### 恢复速度
用了一个毫无意义的图表示收敛趋势和FE接近，同时承认了Eraser是上界。
FedRecovery起伏很大。
同时还评估了每轮恢复的时间，但为什么没有总共的时间
![[Pasted image 20240710172950.png|400]]

##### 测试集准确率
后门恢复，不如FE，高于FR
Trim显然不如FE

##### 对中毒攻击的恢复能力
后门攻击直接看ACC
MISR也有所降低

##### 文章的选择性和自适应分析
显然round越多越好，前面之所以客户端比例0.7，是因为0.7效果最好
敏感性分析阈值β越高，下降越严重，一定的trade-off之后0.3最好

<font color="#ff0000">But除了速度指标外，所有的metrics都不如FE</font>

### Comments
很一般的文章，运气好能中个C
文章试图解决FE高计算和高存储问题，使用了选择性存储历史信息以及自适应回滚，同时还进行了一部分的理论证明，在效率方面有所提升。然而，该方法下降的性能有点多，数据集过于简单。


