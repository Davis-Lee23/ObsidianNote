看定义和方法

<font color="#ff0000">区别，难点，挑战，分类，以及现有技术、现有方案存在的缺陷</font>
## 快速图解
此处又补充了MU的目的：从训练模型中消除特定数据点的影响，同时保持模型的整体性能。
如下图所示MU期望通过遗忘达到和重训练一样的性能，如果可以这是非常cost-effective的。
![[Pasted image 20240131142420.png]]
![[Pasted image 20240131143345.png]]
被遗忘的可以是Client部分数据，也可以是整个Client

## 定义
简单定义：
FU是一种在FL环境中应对数据删除挑战的方法。它的目标是使FL模型删除一个FL客户端或与客户端部分数据相关的可识别信息的影响，同时保持分布式学习过程的隐私保证。

**Formal Definition：**
记FL客户端集合为U,u<sub>i</sub>∈U,每个u<sub>i</sub>有本地数据集D<sub>i</sub>。
U=U<sub>r</sub>∪U<sub>u</sub>，(r=remaining clients，u=unlearning clients)
更具体可表示为，对任意u<sub>j</sub>∈U<sub>u</sub>，Ḋ<sub>j</sub>代表要被遗忘部分
1. 若Ḋ<sub>j</sub>=D<sub>j</sub>代表遗忘整个客户端
2. 若Ḋ<sub>j</sub>∈D<sub>j</sub>代表遗忘客户端u<sub>j</sub>部分数据
联邦遗忘过程FU(M,U,U<sub>r</sub>,U<sub>u</sub>)
Ṁ：经过FL(U)训练后的遗忘模型
Ḿ：retrained model(U=U<sub>r</sub>∪U<sub>u</sub>,ui∈Ur posses D<sub>i</sub>,u<sub>j</sub>∈U<sub>u</sub> posses Dj\\Ḋ<sub>j</sub>)
该函数中的U包括U<sub>r</sub>,U<sub>u</sub>,其中u<sub>j</sub>∈U<sub>u</sub>包含Ḋ<sub>j</sub>
目标：Ṁ的性能能与Ḿ相当

## 与中心化的区别

1. MU是针对一个client，FU是多个client。因此FU执行遗忘算法者不一定是目标客户端(被遗忘者本身)，也可以是其他客户端、服务器。
2. 相比于中心化MU，实现模型一致性更加复杂。此外，需要遗忘所有受影响客户端，这也增添了成本。挑战1
3. 中心化MU直接访问数据，而FU无法直接访问数据，这违背了FL初衷。挑战2
4. 安全性方面，FU更加复杂

## 挑战（FU）
##### 期望的目标
1. Model Consistency：性能和再训练的一样好。
2. Unlearning efficiency：训练时间显著缩短。
3. Privacy preservation：保证原有FL隐私保护功能存在，即保护本地客户端隐私。
4. Certified removal：认证遗忘部分必须与FL参与者提出的遗忘请求一致，保证系统可信。
后续目标1,2,3,4分别对应上述目标
要实现上述目标，有以下挑战
##### 挑战
1. **Knowledge Permeation知识渗透**
	+ 当要删除数据时，它的信息已经传播在FL系统中了。相比于中心化MU，这使目标1更加复杂。此外，需要遗忘所有受影响客户端，这也为目标2增添了成本。
2. **Data Isolation 数据隔离**
	+ FL让各方保存自己的数据仅公开梯度和共享模型。这原本是FL的优势，然而这阻碍了已有MU算法直接访问数据的做法，这有悖于目标3。
	+ 相比直接访问，我们需要其他方法协助实现遗忘，这也可能导致开销增大(不利于目标2)
3. **Who-Unlearn "谁"去遗忘**
	+ MU仅需遗忘特定的单个客户端，而FU系统有多种参与者可选：① 遗忘客户端(目标客户端)② 其余客户端③ 中央服务器。这三者都可以执行遗忘算法，选择谁去执行需要满足目标3。举例：
		1. 情况一：某个客户端要遗忘部分数据，此时要限制服务器和其他客户端权限
		2. 情况二：要遗忘整个客户端，此时服务器和其余客户端都可以执行遗忘算法。
	+ 遗忘算法执行方要确保符合被遗忘者的提出的遗忘需求，以满足目标4
4. **Unlearn-What 遗忘什么**
	+ 一般分为两种：遗忘整个客户端，或客户端中某些特定数据。对于这两种情况要采用的算法将会有很大差别。
## 难点（FL）
除了上面FU的挑战外，还有一些FL本身存在的难点限制了FU。
1. Constrained Resources:FL本身存在计算、通讯、存储开销，很可能限制资源密集型(resource-intensive)MU算法
2. Participant Heterogeneity:FL客户端存在异质性，例如数据方面的垂直分区特征和Non-IID数据，需要具有异构性感知的联邦遗忘方法。
3. Client Dynamics：每轮FL随机选择客户端参与聚合，并且可能存在大量客户端的加入和推出
4. Security and Privacy Threats：相对于单点MU，FU更为复杂。潜在的恶意攻击和信息泄露更加复杂。

## 分类

### 快速图解
可以概括为两大类：发出请求直接退出的为消极，没退出参与遗忘过程的为积极
![[Pasted image 20240201110659.png]]

结合挑战、遗忘方法的直观分类图解
![[Pasted image 20240201110913.png]]
### Unlearning Principles
1. **Fine-tuning:** 用剩余客户端优化模型，减小目标客户端的影响。
2. **Gradient Ascending** :一个反向机器学习的过程。去最大化损失函数，不过要注意catastrophic forgetting现象。
3. **Multi-task unlearning:** 不仅要消除遗忘数据的影响，而且要加强从剩余数据中获取知识的能力。目前大多研究致力于擦除效应erasure effect和保留效应retention effect的平衡。
	+ **Erasure Effect（抹除效应）**：这是指在多任务学习中，一个任务的学习可能会对另一个任务的性能产生负面影响。换句话说，当模型在一个任务上表现得很好时，它可能会“忘记”或者“抹去”在另一个任务上学到的知识，因为模型在尝试优化所有任务的总体性能时，可能会导致某些特定任务的性能下降。
	+ **Retention Effect（保留效应）**：这与抹除效应相反，指的是在多任务学习中，模型能够保留并利用在一个任务上学到的知识来帮助改善在另一个任务上的性能。这种效应体现了知识共享和转移学习的优势，即通过共同学习多个相关任务，可以提高所有任务的学习效率和性能。
4. **Model scrubbing:** 通常用于去除部分数据。采用了“scrubbing" transformation ℋ使遗忘模型有近似再训练模型的性能。ℋ应用了损失函数的二次逼近，该方法运用了Hessian矩阵，然而实际上对于高维模型难以运用，基本上是使用近似于海森矩阵的方法。
5. **Synthetic data** :用人工合成的数据替代确切的数据达到遗忘效果
### Passive unlearning
##### Server-standalone unlearning
这一类方法通常利用历史数据如梯度，全局模型等来进行遗忘。
+ 已有方法
	1. FedRecovery采用fine-tuning
	2. Crab基于FedRecovery提升了两个方面，一是可选部分历史数据而非全选，二是选择未受到显著影响的模型来进行恢复，而不是初始模型。
	3. 也有人直接平均剩余客户端模型来消除目标客户端影响。
	4. 为了降低直接平均带来的精度损失，又有人使用了知识蒸馏knowledge distillation,这种技术通常配合multi-task unlearning使用。
	5. 在VERIFI中，采用放大剩余客户端梯度以减小目标客户端影响，实现遗忘。
	6. 此外还有联邦随机森林训练的内容，RevFRF：
			![[Pasted image 20240201162315.png]]
	7. 在SCMA中每个客户端维护一个向量来表示本地聚类结果，分配零向量给客户端以实现遗忘。

+ Limitations
	1. 过于依赖历史信息，无法得到遗忘过程中的实时输入，不适用于动态环境
	2. 性能略低于client-aided unlearning
	3. 可能不适用于复杂ML模型和Non-IID FL环境

##### Client-aided unlearning
客户端辅助被认为有更大的潜力，剩余客户端能提供剩余数据的有价值信息，增强遗忘过程。**这种方法服务器访问或不访问历史信息都可以。**
FedEraser像是在用服务器存储换效率
+ 已有方法：
	1. FedEraser：像是空间换时间的思路。每隔t时间保存梯度Gt，遗忘掉目标客户端的梯度之后，用模型M一步步再训练。(怎么有点像加速版retrain)
		![[Pasted image 20240201175121.png]]
	2. FRU在FedEraser基础上只保留重要的更新，提高了效率。
	3. FedRecover也采用了存储历史梯度和全局模型。为了避免剩余客户端采用fine-tuning造成巨大开销，此处在服务器使用Hessian矩阵结合L-BFGS缓存。不过这样做存在误差，剩余客户端周期性地进行计算来纠正误差。(这块没细看)
	4. SIFU采用一种直接的再训练方法。通过从历史贡献计算得出的有界敏感性指标来识别最新的全局模型。剩余客户端将基于所识别的模型进行再训练。
	接下来是一些不依赖于历史更新的方法。
	5. SFU用目标客户端提供的梯度信息和其他客户端提供的表示矩阵信息来细化全局模型。
	6. KNOT根据训练时间和模型稀疏性分组为集群；FedCIO根据数据数据分布划分集群。遗忘时只需重训练某个集群。
	7. HDUS：没有采用传统的中心化结构。每个模型保存邻接客户端的蒸馏模型，称为seed model。当遗忘请求发出，直接删除种子模型。
	![[Pasted image 20240201223804.png]]
+ Limitations
	1. Client-aided unlearning本质上依赖于剩余客户端的参与及其更新，在客户端波动的动态环境中可能成为一个潜在漏洞。
	2. 受FL系统带宽以及剩余客户端的资源限制，效率依然不高。
	3. 综上该种方法不适用于客户端频繁更换或系统资源有限的cross-device场景中


### Active Unlearning
主动遗忘指的是目标客户端积极参与遗忘过程，可以选择留下或离开，是否需要verification。由于目标客户端可以直接访问数据，这种方法目前被认为前景更大。

##### Unlearn partial data.
+ 已有方法
	1. 重训练是最直接的方法。为了减少成本，有一种思路是回滚到全局模型被目标客户端显著影响之前。思路类似于SIFU，此外SCMA也可以运用于此
	   典例：Exact-Fun,ViFLa(环结构)
	   2. Fine-tuning和multi-task learning是目前FU的主流方法。
		   1. FRAMU中服务器聚合来自所有客户端的本地模型和注意力分数，基于此过滤遗忘数据点并更新全局模型
		   2. FedLU是为knowledge graph设计的方法，聚合了嵌入而不是梯度。
		   3. FedME损失基于MIA-like评估模型
	3. Model scrubbing
		1. 有人用近似对角经验Fisher信息矩阵(FIM)提高计算效率。
		2. 在Forsaken,计算虚拟梯度以将未学习模型的置信向量与完全未学习模型中的置信向量对齐。
		3. Forsanken+最小化要遗忘的数据的后验与非成员数据的后验之间的距离。
		4. FFMU将遗忘视作数据集的扰动，用Random smoothing获得更平滑的模型模拟遗忘。其思想与提出梯度平滑和梯度量化的PCMU一致。此外FFMU还用非线性函数克服了不能直接访问客户端的问题。（这块没有很理解）
	4. Synthetic data and gradient ascend
		1. FedAF：用合成标签替代遗忘标签。
			![[Pasted image 20240202171423.png]]
		2. 也有人用梯度上升去研究后门攻击
	5. 也有人研究一些用于贝叶斯联邦学习系统的方法
	6. 也有利用量化和pruning剪枝技术去遗忘特定类别数据的做法。
+ Limitations
	1. 复杂度高。仅删除特定数据，保持剩余数据的模型性能通常需要复杂的算法，这导致计算和通信成本增加。
	2. 可能受到基于over-unlearning攻击，若剩余数据已中毒，中毒会加剧。

##### Unlearn entire client
+ 已有方法
	1. 梯度上升适用于部分和全部的情景。相较于之前最小化损失函数，现在要最大化损失函数，同时为了避免产生随机模型，用其他模型的均值作为参考模型，并设置一个边界。
	2. 也有人采用model scrubbing. 为提高效率，有人采用泰勒展开和预训练DNN来近似海森矩阵
+ Limitations
	1. **与寻常逻辑不符合。** 这种方法限制来源于被遗忘者，因为在这种情况下，客户端要留在系统中进行遗忘，这与常见的请求后离开差别很大。
	2. **低效。** 此外，它还需要剩余客户端一起参与，这不符合效益，尤其在资源受限和大规模FL系统之中。

### Verification
在消极遗忘的服务器单独遗忘中的VERIFI方法中，提供了遗忘者验证的权力the right to verify (RTV)。请求者理应具有验证遗忘效果的能力。
+ Client-side
	1. 遗憾的是给予客户端验证权力的研究非常少。在EMA中通过正确性，置信度和负熵设置了一个阈值进行判断。
	2. VERIFI则是提供了两种非侵入性验证方法，用标记将数据识别为遗忘记忆和错误记忆，通过检测模型在标记上的性能来验证是否成功遗忘。这种方法不会像后门攻击一样操控原始数据。
+ Server-side
	1. FRAMU以两个连续的全局模型差异小于阈值时为界限。
	2. KNOT根据验证准确率和标准差得出遗忘结论。
	3. ViFLa和SCMA当模型收敛就视为遗忘。
	4. FedLU依赖于从知识中得出的预测结果。
	5. FFMU评估数据删除是否超过认证预算。
+ Verification metrics
	+ 评估遗忘算法性能的指标很多。基于准确性的度量是对未学习数据进行评估时最常用的度量标准。
	+ 用运行时间判断遗忘算法效率。
	+ 验证方面可通过后门攻击，推理攻击。
	+ 再训练模型和遗忘模型的性能差异也是指标之一。

--- 

自主学习

### 各种定义
##### 联邦学习
再来捋一遍流程，首先参与者分为两类
1. Client记作U=u1,u2...，对应数据集D1,D2...
2. 中央服务器记作S
训练流程：
1. 局部训练：u<sub>i</sub>用数据集Di训练自己的模型M<sub>i</sub>
2. 模型上传：每个客户端ui上传训练后的Mi给S
3. 模型聚合：S收集并聚合模型更新全局模型M
4. 模型更新：S广播M到所有客户端



## 未来展望

### Privacy-preserving FU 隐私保护
+ 目前绝大多数FU都依赖于客户端的梯度信息，而原则上只有数据拥有者才有这些信息，但是全局模型、恶意攻击者可以通过梯度推测出数据。
+ 我们常用同态加密，多方计算，差分隐私等技术助力隐私保护，但是这些方法会很大程度上影响FU算法性能，因此急需一个高效的隐私保护FU方法。
+ MU可能带来额外的安全问题，如推测原始模型和遗忘模型的差异从而得到数据。这种潜在的风险也应该在FU中考虑。

### Verification & proof of unlearning 遗忘的验证
正如在分类的验证部分所说，目前对于验证的研究很少。
+ 绝大多数情况下遗忘请求都由特定客户端发出，因此应重视客户端验证研究方向。非入侵性方法是一个值得参看的研究领域(如VERIFI的标记方法)
+ proof of unlearning可以在verification难以使用的环境或不可信的环境下使用，文章中提到了两种密码学方法。
	1.  密码学方向的Zero-Knowledge Proofs零知识验证
	2. 交叉结合偏硬件方向的Trusted Execution Environments可信执行环境

### Awareness of client-dynamics 客户端动态变化
**动态感知的FU算法是一个重要的领域。**
1. 相比于集中式MU，FU由于每轮全局聚合客户端潜在的加入和退出，增加了很多不确定性。
	+ 举例：我们需要遗忘的数据来自于一个早已退出的客户端，这很具有挑战性。
2. 隐私保护FU方案也要为动态客户端提供弹性，使得隐私保护方案更加难以设计。

### Domain-specific applications
缺乏实际落地场景。
文章举例了几个MU应用场景用以参考：LLM，推荐系统，用于GNN的隐私问题。

### Fairness and explainability 公平与可解释性
由于FL是分布式的，MU是较为复杂的，因此公平(FL)与可解释性(MU)很重要。
1. 数据在不同客户端重叠是一种很常见的现象。在遗忘数据时不能对到拥有同样数据的客户端产生负面影响。
2. 给FL增加遗忘功能会引入一个复杂的层，系统将更加的复杂。应确保有理解和解释模型的决策过程的能力，并要提升系统透明度、可信度以及遵守法规。