通过模型操纵对联邦学习进行大规模数据重构攻击

FedSGD是特殊的FedAvg，即local epoch=1，全部聚合的avg

# Authors
Joshua C. Zhao，普渡大学为主，南加州为辅
领域为分布式学习（联邦）和拜占庭鲁棒，以及对抗机器学习。对对抗鲁棒性和泛化准确率tradeoff感兴趣。
普渡大学博四，3A（CVPR+SP）+2B（DSN+TODAES）+1C（ACM AsiaCCS）
[Joshua C. Zhao (joshuaczhao.github.io)](https://joshuaczhao.github.io/)

# Abstract
**背景：** 共享的梯度也包含隐私，攻击者可通过对模型和参数的恶意修改或者优化近似梯度得到数据来获取知识，即数据重构。
**动机：** 现有攻击方法在FedAvg更偏向真实场景设置和安全聚合的情况下难以生效，且将攻击限制在单客户端梯度上。言外之意，当前还没有工作能够在AVG+安全聚合共同使用的情况下攻击多个客户端。
**方法：** 提出攻击方法LOKI，克服了之前的限制且打破了聚合的匿名性。具体设计是向客户端发送定制卷积参数，即使聚合之后客户端之间的数据点的权重梯度也保持独立
**结果：** 在100客户端设置下，过去的攻击只能泄露1%，而LOKI可以76%-86%


# Introduction
第一段：介绍FL，FedSGD与FedAvg，基于通信效率avg使用更多
第二段：哪怕是恶意服务器，FL也应当有隐私保护的能力，然而属性推理、成员推理、GAN都可以从共享梯度推理出客户端数据，尤其是**重构攻击**，甚至可以跨越最严格的防御。

第三段：一类重构攻击为**Optimization attacks**，随着batchsize和图像分辨率提高，优化攻击越难，大部分只在FedSGD生效，最新工作在Avg也生效具有前景。
第四段：**安全聚合**有效的防御了此类攻击，因为服务器只能访问所有客户端更新的聚合。
第五段：另一类叫解析重构攻击，涉及自定义模型参数或模型架构，以直接从全连接 （FC） 层的梯度中检索训练数据，称作linear layer leakage。对于安全聚合的FedSGD，增加注入的FC层大小可以保持高泄露率，但对安全聚合的avg没法子。

第六段：各种研究都没用，无人做到在**Avg+安全聚合**的情况下攻击**多个客户端**。

本文工作：LOKI，一种攻击方法：恶意服务器可以仅使用聚合更新在一次迭代中直接重建多个用户的训练数据，且在SGD和AVG都生效。
核心思想：服务器发送定制的卷积核给各个客户端，这样每个客户端输入数据的梯度在聚合之后仍然是可分离的，服务器可以借此恢复他们。
还引入了一个split scaling

后面听起来很牛逼啊，一遍不能完全懂。

贡献总结：
1. 提出LOKI，在安全聚合+Avg情况下仍然可以进行重构，并且可以明确样本来自哪个客户端
2. 通过split scaling，可以无视客户端数量和batch大小
3. 通过卷积缩放因子，LOKI能够防止不同局部迭代之间的图像激活同一神经元，这是 FedAVG 线性层泄漏的一个基本问题。这使得loki泄露率更高
4. LOKI在noniid中可用，在OrganAMNIST甚至可达62.3%

# Background了解
重建攻击的核心理念就是打破FL对于隐私的基本原则，即通过updates就可以得到客户端data。
类别有优化、分析攻击、线性层泄露、GANs，但大都只关注单客户端以及聚合后的梯度。


# Experiments
### Setup
数据集：CIFAR-100，Tiny ImageNet，MNIST
leakage module使用ResNet-50
一些看不太懂的实验设置。

这个真得从头开始看